# -*- coding: utf-8 -*-
"""Copy of breathing1

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1eY0k4gMEfCvwEvK-ZfByPArqqj0OkPrq
"""

import numpy as np
import cv2
import os
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.keras.optimizers import Adam

from keras.models import clone_model
from keras.models import Sequential
from keras.activations import relu
from tensorflow.keras.applications.mobilenet import MobileNet
from tensorflow.keras.applications.resnet import ResNet50
from tensorflow.keras.applications.vgg16 import VGG16
from keras.layers import Dense, Conv2D, Flatten, add, BatchNormalization, Input
# import tensorflow_addons as tfa
import random
import sklearn
import time
from sklearn import metrics
#from tensorflow import contrib
#from tensorflow.contrib import lite
# from sklearn.model_selection import cross_val_score
# from sklearn.pipeline import make_pipeline
# from sklearn.preprocessing import StandardScaler
# from sklearn.svm import SVC
# from sklearn.ensemble import RandomForestClassifier
# from sklearn.model_selection import StratifiedKFold
from keras.models import load_model
import seaborn as sns
import matplotlib.pyplot as plt 
from google.colab import drive
drive.mount('/content/drive')

!pip install tensorflow-addons
!pip install --upgrade tensorflow

!pip install tensorflow==2.7.0

!pip install numpy --upgrade



def crop(im):
 
    copy = im
    im_gray = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY);
    im_gray1 = 255-im_gray
    im_gray2 = cv2.threshold(im_gray1, 0, 255, cv2.THRESH_OTSU+cv2.THRESH_BINARY)[1]
    cnts = cv2.findContours(im_gray2, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    cnts = cnts[0] if len(cnts) == 2 else cnts[1]
    cnts = sorted(cnts, key=cv2.contourArea, reverse=True)

    for c in cnts:
        x,y,w,h = cv2.boundingRect(c)
        cv2.rectangle(im, (x, y), (x + w, y + h), (36,255,12), 2)
        ROI = copy[y+2:y+h-2, x+2:x+w-2]
        break

    img = ROI
    return ROI

def doKfold(xtest, ytest ,k):
    dataset = []
    dataset_split = []
    for i in range(len(xtest)):
      dataset.append((xtest[i],ytest[i]))
    random.seed(69)
    random.shuffle(dataset)
    foldsize = len(dataset) // k
    j = 0
    for i in range(k):
      fold = []
      while len(fold) < foldsize: 
             fold.append(dataset[j])
             j=j+1
      dataset_split.append(fold)
    return dataset_split

def getResamples(splitdataset, index):
  train=[]
  test=[]
  xtrain=[]
  xtest=[]
  ytrain=[]
  ytest=[]
  for i in range(len(splitdataset)):
    if i == index:
      test.extend(splitdataset[i])
    else:
      train.extend(splitdataset[i])
  for i in range(len(train)):
    xtrain.append(train[i][0])
    ytrain.append(train[i][1])
  for i in range(len(test)):
    xtest.append(test[i][0])
    ytest.append(test[i][1])
  xtrain=np.array(xtrain)
  ytrain=np.array(ytrain) 
  xtest=np.array(xtest)
  ytest=np.array(ytest) 
  return (xtrain,ytrain),(xtest,ytest)

def getdata():
  xtrain=[]
  xtest=[]
  ytrain=[]
  ytest=[]
  xval=[]
  yval=[]

  # path='/content/drive/MyDrive/imgs2/train/'
  # names=os.listdir(path)
  # for name in names:
  #   im=cv2.imread(path+name)
  #   output=crop(im)
  #   typeim=name.split(' ')[0]
  #   if typeim=='whighn':
  #     ytest.append(2)
  #   elif typeim=='wNormaln':
  #     ytest.append(1)
  #   else: 
  #     ytest.append(0)
  #   im=cv2.resize(output,(128,128))           #in synchro output instead of im
  #   xtest.append(im/255)
  # xtest=np.array(xtest)
  # ytest=np.array(ytest)
  # ytest=np.reshape(ytest,(ytest.shape[0],1))


  path='/content/drive/MyDrive/CWT/train/' 
  names=os.listdir(path)
  for name in names:
    im=cv2.imread(path+name)
    output=crop(im)
    typeim=name.split("_B")[0]
    if typeim=='22_5':
      ytrain.append(5)
    elif typeim=='20':
      ytrain.append(4)
    elif typeim=='17_5':
      ytrain.append(3)
    elif typeim=='15':
      ytrain.append(2)
    elif typeim=='12_5':
      ytrain.append(1)
    else: 
      ytrain.append(0)
    im=cv2.resize(output,(128,128))          #in synchro output instead of im
    xtrain.append(im/255)
  xtrain=np.array(xtrain)
  ytrain=np.array(ytrain)
  ytrain=np.reshape(ytrain,(ytrain.shape[0],1))


  path='/content/drive/MyDrive/CWT/val/'
  names=os.listdir(path)
  for name in names:
    im=cv2.imread(path+name)
    output=crop(im)
    typeim=name.split("_B")[0]
    if typeim=='22_5':
      yval.append(5)
    elif typeim=='20':
      yval.append(4)
    elif typeim=='17_5':
      yval.append(3)
    elif typeim=='15':
      yval.append(2)
    elif typeim=='12_5':
      yval.append(1)
    else: 
      yval.append(0)
    im=cv2.resize(output,(128,128))           #in synchro output instead of im
    xval.append(im/255)
  xval=np.array(xval)
  yval=np.array(yval)
  yval=np.reshape(yval,(yval.shape[0],1))

  
  return (xtrain,ytrain),(xval,yval)

input_shape=(128,128,3)
(xtrain,ytrain),(xval,yval)=getdata()
splitdata = doKfold(xtrain, ytrain,10)
print(len(splitdata))
print (xtrain.shape)
# print (xtest.shape)
print (ytrain.shape)
# print (ytest.shape)
print (xval.shape)
print (yval.shape)

def getmodel():
  input=layers.Input(shape=input_shape)
  x=layers.Conv2D(32,3,strides=1)(input)
  x=layers.BatchNormalization()(x)
  x=layers.MaxPool2D()(x)
  x=layers.Dropout(0.3)(x)
  x=layers.ReLU()(x)
  # x=layers.Conv2D(32,3)(x)
  # x=layers.MaxPool2D()(x)
  # x=layers.ReLU()(x)
  x=layers.Conv2D(64,3,strides=1)(x)
  x=layers.BatchNormalization()(x)
  x=layers.MaxPool2D()(x)
  x=layers.Dropout(0.4)(x)
  x=layers.ReLU()(x)
  # x=layers.Conv2D(64,3)(x)
  # x=layers.MaxPool2D()(x)
  # x=layers.ReLU()(x)
  # x=layers.Conv2D(128,3,strides=1)(x)
  # x=layers.MaxPool2D()(x)
  # x=layers.ReLU()(x)
  x=layers.Conv2D(128,3)(x)
  x=layers.BatchNormalization()(x)
  x=layers.MaxPool2D()(x)
  x=layers.Dropout(0.2)(x)
  x=layers.ReLU()(x)
  x=layers.Flatten()(x)
  x=layers.Dense(128,activation='relu')(x)
  x=layers.Dropout(0.1)(x)
  x=layers.Dense(128,activation='relu')(x)
  x=layers.Dropout(0.1)(x)
  x=layers.Dense(64,activation='relu')(x)
  x=layers.Dropout(0.1)(x)
  x=layers.Dense(64,activation='relu')(x)
  x=layers.Dropout(0.1)(x)
  output=layers.Dense(6,activation='softmax')(x)
  model=keras.Model(inputs=input,outputs=output)
  model.compile(loss=keras.losses.SparseCategoricalCrossentropy(),optimizer=Adam(learning_rate=0.00001),metrics='accuracy')
  return model

def trainModel(model,xtrain,ytrain,xtest,ytest):
    modelcp = clone_model(model)
    modelcp.compile(loss=keras.losses.SparseCategoricalCrossentropy(),optimizer=Adam(learning_rate=0.00001),metrics='accuracy')
    history = modelcp.fit(xtrain,ytrain,validation_data=(xval,yval),batch_size=16,epochs=100)
    return modelcp, history

models=[]
model=getmodel()
model.summary()
for i in range(10):
  (xtrain,ytrain),(xtest,ytest)=getResamples(splitdata,i)
  print("training fold no",i)
  (modelcp),(history)=trainModel(model,xtrain,ytrain,xval,yval)
  models.append((modelcp,history))
  modelcp.save('/content/drive/MyDrive/Models/model'+str(i+1)+'.h5')

def predict(models, xtest):
  preds=[]
  result=[]
  for model in models:
    ytest=model[0].predict(xtest)
    ytest = np.argmax(ytest,axis= 1)
    preds.append(ytest)
  for i in range(len(xtest)):
    arr=[0,0,0,0,0,0]
    for j in range(len(models)):
      arr[preds[j][i]]+=1
    arr=np.array(arr)
    result.append(arr)
  return np.argmax(result,axis=1)

(xtrain,ytrain),(xtest,ytest)=getResamples(splitdata,1)
y_pred=predict(models,xtest)
cf = metrics.confusion_matrix(ytest, y_pred, labels = [0, 1, 2,3,4,5])
print(cf)

X = np.concatenate((xtrain, xtest,xval), axis = 0)
Y = np.concatenate((ytrain, ytest,yval), axis = 0)
y_pred = modelcp.predict(X)
y_pred = np.argmax(y_pred, axis = 1)
y_pred=predict(models,X)
cf = metrics.confusion_matrix(Y, y_pred, labels = [0, 1, 2,3,4,5])
print(cf)

def genConfusionMatrix(cf, classes, figsize = (6, 6),):
    counts = ["{0:0.0f}".format(value) for value in cf.flatten()]
    labels = [f"{v1}" for v1 in zip(counts)]
    labels = np.asarray(labels).reshape(len(classes), len(classes))
    plt.figure(figsize = figsize)
    sns.set(font_scale=1.4)
    res = sns.heatmap(cf, annot = labels, fmt = '', cmap = 'Blues', xticklabels = classes, yticklabels = classes)
    res.set_xticklabels(res.get_xmajorticklabels(), fontsize = 18)
    res.set_yticklabels(res.get_ymajorticklabels(), fontsize = 18)
    
    plt.title('Confusion Matrix')

classes = ['10_BPM', '12_5_BPM', '15_BPM','17_5_BPM','20_BPM','22_5_BPM']
genConfusionMatrix(cf, classes)

for model in models:
   history=model[1]
   plt.plot(history.history['accuracy'])
   plt.plot(history.history['val_accuracy'])
   plt.title('model accuracy')
   plt.ylabel('accuracy')
   plt.xlabel('epoch')
   plt.legend(['train', 'val'], loc='upper left')
   plt.show()

for model in models:
   history=model[1]
   plt.plot(history.history['loss'])
   plt.plot(history.history['val_loss'])
   plt.title('model loss')
   plt.ylabel('loss')
   plt.xlabel('epoch')
   plt.legend(['train', 'val'], loc='upper left')
   plt.show()

modelcp.evaluate(xval,yval)